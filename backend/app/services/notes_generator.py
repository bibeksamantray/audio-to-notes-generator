import logging
from typing import Optional

import requests

from ..config import settings

logger = logging.getLogger(__name__)


def build_notes_prompt(
    transcript: str,
    title: str,
    course: Optional[str],
    lecturer: Optional[str],
    lecture_date: Optional[str],
) -> str:
    """
    Build a clear prompt for the local LLM to convert a lecture transcript
    into structured, exam-focused notes.
    """
    meta_lines = [f"Title: {title}"]
    if course:
        meta_lines.append(f"Course: {course}")
    if lecturer:
        meta_lines.append(f"Lecturer: {lecturer}")
    if lecture_date:
        meta_lines.append(f"Date: {lecture_date}")

    metadata_str = "\n".join(meta_lines)

    prompt = f"""
You are an expert teaching assistant.

Your task is to read a lecture transcript and produce well-structured lecture notes that a college student can study from.

### Metadata
{metadata_str}

### Requirements for the NOTES:
- Start with a short 2-3 sentence overview of the lecture.
- Use clear section headings (e.g., "Introduction", "Key Concepts", "Examples", "Summary").
- Use bullet points for lists.
- Highlight definitions, formulas, and important concepts.
- Ignore filler words and transcription noise.
- Do NOT invent facts that are not supported by the transcript.
- Write in English and keep the style concise and exam-focused.

### Output Format
Return the notes in markdown-like text with headings and bullet points.

### Lecture Transcript (verbatim)
\"\"\" 
{transcript}
\"\"\"

Now produce the lecture notes.
"""
    return prompt.strip()


def generate_notes_with_ollama(
    transcript: str,
    title: str,
    course: Optional[str],
    lecturer: Optional[str],
    lecture_date: Optional[str],
) -> str:
    """
    Call a local Ollama server to generate lecture notes from a transcript.

    Assumes Ollama is running and the configured model is available.
    """
    prompt = build_notes_prompt(transcript, title, course, lecturer, lecture_date)

    url = f"{settings.LLM_API_BASE_URL}/api/generate"
    payload = {
        "model": settings.LLM_MODEL_NAME,
        "prompt": prompt,
        "stream": False,
    }

    logger.info(
        "Requesting notes from Ollama model '%s' at '%s'...",
        settings.LLM_MODEL_NAME,
        url,
    )

    try:
        response = requests.post(url, json=payload, timeout=600)
        response.raise_for_status()
        data = response.json()
        notes_text = data.get("response", "").strip()
        if not notes_text:
            raise RuntimeError("Received empty notes from LLM.")
        logger.info("Notes successfully generated by LLM.")
        return notes_text
    except Exception as exc:  # broad for robustness, logged for debugging
        logger.exception("Failed to generate notes via LLM: %s", exc)
        raise

